{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "spam = []\n",
    "\n",
    "ham_files = [f for f in os.listdir(\"data/train/ham\")]\n",
    "spam_files = [f for f in os.listdir(\"data/train/spam\")]\n",
    "\n",
    "for f in ham_files:\n",
    "    with open(\"data/train/ham/\" + f, 'r', encoding='latin1') as myfile:\n",
    "        content = myfile.read()\n",
    "        corpus.append(content)\n",
    "        spam.append(0)\n",
    "        \n",
    "for f in spam_files:\n",
    "    with open(\"data/train/spam/\" + f, 'r', encoding='latin1') as myfile:\n",
    "        content = myfile.read()\n",
    "        corpus.append(content)\n",
    "        spam.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam is like: [0,0,0 .... 1,1,1]. Cross validation will fail on this distribution. So we need to shuffle corpus and spam identically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42) # without it, shuffle_lists() would make the results unstable.\n",
    "\n",
    "def shuffle_lists(a, b):\n",
    "    c = list(zip(a, b))\n",
    "    random.shuffle(c)\n",
    "    a, b = zip(*c)\n",
    "    return a, b\n",
    "\n",
    "corpus, spam = shuffle_lists(corpus, spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature engineering within Transformation Pipeline\n",
    "\n",
    "We will defines different steps to prepare our data:\n",
    "- HeaderDeletor: Delete email header.\n",
    "- UrlsDeletor: Replace urls by URL.\n",
    "- NumberDeletor Replace numbers by NUMBER .\n",
    "- Vectorizor: vectorize an email. As option we can also apply downcase and stemming.\n",
    "- Predictor: Fit a model (Stochastic Gradient Descent) and predict new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class HeaderDeletor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, delete_header):\n",
    "        self.delete_header = delete_header\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.delete_header:\n",
    "            def delete_header(x):\n",
    "                try:\n",
    "                    return x.split(\"\\n\\n\")[1]\n",
    "                except IndexError:\n",
    "                    return \"\"\n",
    "                \n",
    "            return list(map(delete_header, X))\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class UrlsDeletor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, skip=False):\n",
    "        self.skip = skip\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.skip:\n",
    "            return X\n",
    "        else:\n",
    "            def replace_urls(x):\n",
    "                return re.sub(r'http\\S+', 'URL', x)\n",
    "            return list(map(replace_urls, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class NumberDeletor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, skip=False):\n",
    "        self.skip = skip\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.skip:\n",
    "            return X\n",
    "\n",
    "        def clearup(s):\n",
    "            return re.sub(r'[0-9]+', 'NUMBER', s)\n",
    "        \n",
    "        return list(map(clearup, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "\n",
    "class Vectorizor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lowercase=True, skip_stemming=False):\n",
    "            stemmer = EnglishStemmer()\n",
    "            analyzer = CountVectorizer().build_analyzer()\n",
    "            def stemmed_words(doc):\n",
    "                return (stemmer.stem(w) for w in analyzer(doc))\n",
    "            if skip_stemming:\n",
    "                self.vectorizor = CountVectorizer(lowercase=lowercase)\n",
    "            else:\n",
    "                self.vectorizor = CountVectorizer(lowercase=lowercase, analyzer=stemmed_words)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizor.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.vectorizor.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "class Predictor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.sgd_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.sgd_clf.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.sgd_clf.transform(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.sgd_clf.predict(X)\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        return self.sgd_clf.decision_function(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.sgd_clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "lowercase = True\n",
    "delete_header = False\n",
    "skip_url = True\n",
    "skip_number = False\n",
    "skip_stemming = False\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('header_deletor', HeaderDeletor(delete_header=delete_header)),\n",
    "        ('url_deletor', UrlsDeletor(skip=skip_url)),\n",
    "        ('number_deletor', NumberDeletor(skip=skip_number)), \n",
    "        ('vectorizer', Vectorizor(lowercase=lowercase, skip_stemming=skip_stemming)),\n",
    "        ('predictor', Predictor())\n",
    "    ])\n",
    "\n",
    "params_grid = [\n",
    "    {\n",
    "        'header_deletor__delete_header': [True, False],\n",
    "        'url_deletor__skip': [True, False],\n",
    "        'number_deletor__skip': [True, False],\n",
    "        'vectorizer__lowercase': [True, False],\n",
    "        'vectorizer__skip_stemming': [True, False]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fine-tuning of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/geoffroy.gobert/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951096452021 0.207708207527 {'header_deletor__delete_header': True, 'number_deletor__skip': True, 'url_deletor__skip': True, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': True}\n",
      "0.951096452021 0.207708207527 {'header_deletor__delete_header': True, 'number_deletor__skip': True, 'url_deletor__skip': True, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': False}\n",
      "0.951096452021 0.207708207527 {'header_deletor__delete_header': True, 'number_deletor__skip': True, 'url_deletor__skip': True, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': True}\n",
      "0.951096452021 0.207708207527 {'header_deletor__delete_header': True, 'number_deletor__skip': True, 'url_deletor__skip': True, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': False}\n",
      "0.953742109305 0.208981460492 {'header_deletor__delete_header': True, 'number_deletor__skip': True, 'url_deletor__skip': False, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': True}\n",
      "0.953742109305 0.208981460492 {'header_deletor__delete_header': True, 'number_deletor__skip': True, 'url_deletor__skip': False, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': False}\n",
      "0.953742109305 0.208981460492 {'header_deletor__delete_header': True, 'number_deletor__skip': True, 'url_deletor__skip': False, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': True}\n",
      "0.953742109305 0.208981460492 {'header_deletor__delete_header': True, 'number_deletor__skip': True, 'url_deletor__skip': False, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': False}\n",
      "0.955266005081 0.147431391984 {'header_deletor__delete_header': True, 'number_deletor__skip': False, 'url_deletor__skip': True, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': True}\n",
      "0.955266005081 0.147431391984 {'header_deletor__delete_header': True, 'number_deletor__skip': False, 'url_deletor__skip': True, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': False}\n",
      "0.955266005081 0.147431391984 {'header_deletor__delete_header': True, 'number_deletor__skip': False, 'url_deletor__skip': True, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': True}\n",
      "0.955266005081 0.147431391984 {'header_deletor__delete_header': True, 'number_deletor__skip': False, 'url_deletor__skip': True, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': False}\n",
      "0.974130058435 0.105024079979 {'header_deletor__delete_header': True, 'number_deletor__skip': False, 'url_deletor__skip': False, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': True}\n",
      "0.974130058435 0.105024079979 {'header_deletor__delete_header': True, 'number_deletor__skip': False, 'url_deletor__skip': False, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': False}\n",
      "0.974130058435 0.105024079979 {'header_deletor__delete_header': True, 'number_deletor__skip': False, 'url_deletor__skip': False, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': True}\n",
      "0.974130058435 0.105024079979 {'header_deletor__delete_header': True, 'number_deletor__skip': False, 'url_deletor__skip': False, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': False}\n",
      "0.994850978828 0.0742817532872 {'header_deletor__delete_header': False, 'number_deletor__skip': True, 'url_deletor__skip': True, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': True}\n",
      "0.994850978828 0.0742817532872 {'header_deletor__delete_header': False, 'number_deletor__skip': True, 'url_deletor__skip': True, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': False}\n",
      "0.994850978828 0.0742817532872 {'header_deletor__delete_header': False, 'number_deletor__skip': True, 'url_deletor__skip': True, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': True}\n",
      "0.994850978828 0.0742817532872 {'header_deletor__delete_header': False, 'number_deletor__skip': True, 'url_deletor__skip': True, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': False}\n",
      "0.993900220086 0.0721137485812 {'header_deletor__delete_header': False, 'number_deletor__skip': True, 'url_deletor__skip': False, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': True}\n",
      "0.993900220086 0.0721137485812 {'header_deletor__delete_header': False, 'number_deletor__skip': True, 'url_deletor__skip': False, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': False}\n",
      "0.993900220086 0.0721137485812 {'header_deletor__delete_header': False, 'number_deletor__skip': True, 'url_deletor__skip': False, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': True}\n",
      "0.993900220086 0.0721137485812 {'header_deletor__delete_header': False, 'number_deletor__skip': True, 'url_deletor__skip': False, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': False}\n",
      "0.990630491791 0.105639855876 {'header_deletor__delete_header': False, 'number_deletor__skip': False, 'url_deletor__skip': True, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': True}\n",
      "0.990630491791 0.105639855876 {'header_deletor__delete_header': False, 'number_deletor__skip': False, 'url_deletor__skip': True, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': False}\n",
      "0.990630491791 0.105639855876 {'header_deletor__delete_header': False, 'number_deletor__skip': False, 'url_deletor__skip': True, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': True}\n",
      "0.990630491791 0.105639855876 {'header_deletor__delete_header': False, 'number_deletor__skip': False, 'url_deletor__skip': True, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': False}\n",
      "0.993581863227 0.0870163924226 {'header_deletor__delete_header': False, 'number_deletor__skip': False, 'url_deletor__skip': False, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': True}\n",
      "0.993581863227 0.0870163924226 {'header_deletor__delete_header': False, 'number_deletor__skip': False, 'url_deletor__skip': False, 'vectorizer__lowercase': True, 'vectorizer__skip_stemming': False}\n",
      "0.993581863227 0.0870163924226 {'header_deletor__delete_header': False, 'number_deletor__skip': False, 'url_deletor__skip': False, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': True}\n",
      "0.993581863227 0.0870163924226 {'header_deletor__delete_header': False, 'number_deletor__skip': False, 'url_deletor__skip': False, 'vectorizer__lowercase': False, 'vectorizer__skip_stemming': False}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, params_grid, cv=3, scoring='roc_auc')\n",
    "grid_search.fit(corpus, spam)\n",
    "\n",
    "# Display the results of the GridSearch\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, std_score, params in zip(cvres['mean_test_score'], cvres['std_test_score'], cvres['params']):\n",
    "    print(np.sqrt(mean_score), np.sqrt(std_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best AUC of ROC : 99.48%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "## 4.1 Compromising Precision / Recall\n",
    "In the case of a mail box, it's very important that the friends, work ... emails are not marked as spam. In term of precision and recall that mean: we want to ensure a good precision over a good recall:\n",
    "\n",
    "- Precision: we want to ensure that a spam is correctly detected as spam or not\n",
    "- Recall: it's less important that all the spams are detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = spam_clf.predict(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEKCAYAAADXdbjqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1099b5ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_scores = spam_clf.decision_function(corpus)\n",
    "\n",
    "# Hack because of scikitlearn 0.19\n",
    "if y_scores.ndim == 2:\n",
    "    y_scores = y_scores[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(spam, y_scores)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=\"foo\"):\n",
    "    plt.plot(fpr, tpr, linewidth=5, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 0.1, 0.9, 1])\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ROC AUC is too good to make any compromise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[483,   0],\n",
       "       [  2,  90]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(spam, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe if we had more emails, we would have more classification errors, and we could give a look at the ROC in order to fine-tune the precision recall compromise.\n",
    "\n",
    "But so far so good."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
